{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44e40178",
   "metadata": {},
   "source": [
    "# Intro to sklearn\n",
    "\n",
    "Objectives:\n",
    "\n",
    "- train a model with [sklearn]()\n",
    "- perform a validation test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2bf4e1",
   "metadata": {},
   "source": [
    "## Diabetes dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b3bec6",
   "metadata": {},
   "source": [
    "__Import the diabetes dataset from sklearn. Describe it.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3def177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "data = load_diabetes()\n",
    "X = data['data']\n",
    "Y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26e1a168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, T-Cells (a type of white blood cells)\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, thyroid stimulating hormone\n",
      "      - s5      ltg, lamotrigine\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360a8c3a",
   "metadata": {},
   "source": [
    "__Split the dataset into a training set (70%) and a test set (30%)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94c91ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2665bd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c24e3bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca56e759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3009049773755656"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "133/(133+309)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e72270",
   "metadata": {},
   "source": [
    "Features are already \"centered and scaled\": no need to renormalize them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bff489",
   "metadata": {},
   "source": [
    "__Train a linear model (with intercept) on the training set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e81edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "# by default there is an intercept (check the doc: default value for fit_intercept is True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57b93175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Ordinary least squares Linear Regression.\n",
       "\n",
       "LinearRegression fits a linear model with coefficients w = (w1, ..., wp)\n",
       "to minimize the residual sum of squares between the observed targets in\n",
       "the dataset, and the targets predicted by the linear approximation.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "fit_intercept : bool, default=True\n",
       "    Whether to calculate the intercept for this model. If set\n",
       "    to False, no intercept will be used in calculations\n",
       "    (i.e. data is expected to be centered).\n",
       "\n",
       "normalize : bool, default=False\n",
       "    This parameter is ignored when ``fit_intercept`` is set to False.\n",
       "    If True, the regressors X will be normalized before regression by\n",
       "    subtracting the mean and dividing by the l2-norm.\n",
       "    If you wish to standardize, please use\n",
       "    :class:`~sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
       "    on an estimator with ``normalize=False``.\n",
       "\n",
       "copy_X : bool, default=True\n",
       "    If True, X will be copied; else, it may be overwritten.\n",
       "\n",
       "n_jobs : int, default=None\n",
       "    The number of jobs to use for the computation. This will only provide\n",
       "    speedup for n_targets > 1 and sufficient large problems.\n",
       "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
       "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
       "    for more details.\n",
       "\n",
       "positive : bool, default=False\n",
       "    When set to ``True``, forces the coefficients to be positive. This\n",
       "    option is only supported for dense arrays.\n",
       "\n",
       "    .. versionadded:: 0.24\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "coef_ : array of shape (n_features, ) or (n_targets, n_features)\n",
       "    Estimated coefficients for the linear regression problem.\n",
       "    If multiple targets are passed during the fit (y 2D), this\n",
       "    is a 2D array of shape (n_targets, n_features), while if only\n",
       "    one target is passed, this is a 1D array of length n_features.\n",
       "\n",
       "rank_ : int\n",
       "    Rank of matrix `X`. Only available when `X` is dense.\n",
       "\n",
       "singular_ : array of shape (min(X, y),)\n",
       "    Singular values of `X`. Only available when `X` is dense.\n",
       "\n",
       "intercept_ : float or array of shape (n_targets,)\n",
       "    Independent term in the linear model. Set to 0.0 if\n",
       "    `fit_intercept = False`.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "Ridge : Ridge regression addresses some of the\n",
       "    problems of Ordinary Least Squares by imposing a penalty on the\n",
       "    size of the coefficients with l2 regularization.\n",
       "Lasso : The Lasso is a linear model that estimates\n",
       "    sparse coefficients with l1 regularization.\n",
       "ElasticNet : Elastic-Net is a linear regression\n",
       "    model trained with both l1 and l2 -norm regularization of the\n",
       "    coefficients.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "From the implementation point of view, this is just plain Ordinary\n",
       "Least Squares (scipy.linalg.lstsq) or Non Negative Least Squares\n",
       "(scipy.optimize.nnls) wrapped as a predictor object.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.linear_model import LinearRegression\n",
       ">>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
       ">>> # y = 1 * x_0 + 2 * x_1 + 3\n",
       ">>> y = np.dot(X, np.array([1, 2])) + 3\n",
       ">>> reg = LinearRegression().fit(X, y)\n",
       ">>> reg.score(X, y)\n",
       "1.0\n",
       ">>> reg.coef_\n",
       "array([1., 2.])\n",
       ">>> reg.intercept_\n",
       "3.0000...\n",
       ">>> reg.predict(np.array([[3, 5]]))\n",
       "array([16.])\n",
       "\u001b[0;31mFile:\u001b[0m           ~/.local/opt/miniconda/lib/python3.8/site-packages/sklearn/linear_model/_base.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LinearRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "754ed699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5aef27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Fit linear model.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
       "    Training data\n",
       "\n",
       "y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
       "    Target values. Will be cast to X's dtype if necessary\n",
       "\n",
       "sample_weight : array-like of shape (n_samples,), default=None\n",
       "    Individual weights for each sample\n",
       "\n",
       "    .. versionadded:: 0.17\n",
       "       parameter *sample_weight* support to LinearRegression.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "self : returns an instance of self.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/opt/miniconda/lib/python3.8/site-packages/sklearn/linear_model/_base.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7217fd",
   "metadata": {},
   "source": [
    "__Compute the fitting score on the test set. (Bonus: compare with your own computation of $R^2$)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e63b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "961fb7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([190., 225., 141., 281., 168.,  42., 116., 276., 281.,  51., 121.,\n",
       "       156., 163., 142., 187., 173.,  39., 229., 155., 332., 257., 261.,\n",
       "        42., 201., 103.,  47., 142., 172.,  71.,  96., 173., 127., 150.,\n",
       "       230., 185., 209.,  37.,  92., 235., 131.,  97.,  40., 279.,  97.,\n",
       "       245., 258., 102., 168.,  51., 248.,  88.,  91.,  58., 110., 308.,\n",
       "        88.,  60., 311., 246., 310., 214., 200., 220., 131.,  72.,  72.,\n",
       "       181.,  89., 163., 104.,  96.,  70., 217.,  55., 317., 259.,  50.,\n",
       "       118., 200.,  25., 124., 129., 179., 109.,  71., 102., 252., 189.,\n",
       "       190., 263., 174., 259., 111.,  85., 145.,  85., 252., 258., 274.,\n",
       "        83., 140., 196., 219., 200., 197.,  51.,  66.,  79., 275.,  78.,\n",
       "       257., 180., 202.,  71., 122., 136., 270.,  70., 146., 281., 114.,\n",
       "        59., 191.,  91.,  65., 143., 185., 243.,  53.,  99., 125., 139.,\n",
       "       292.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "048f710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1987ebd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Out of sample test')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Y_test, pred,'o')\n",
    "plt.xlabel(\"True value\")\n",
    "plt.ylabel(\"Prediction\")\n",
    "plt.title(\"Out of sample test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "892d679d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5249868646449161"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd1e2764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return the coefficient of determination :math:`R^2` of the\n",
       "prediction.\n",
       "\n",
       "The coefficient :math:`R^2` is defined as :math:`(1 - \\frac{u}{v})`,\n",
       "where :math:`u` is the residual sum of squares ``((y_true - y_pred)\n",
       "** 2).sum()`` and :math:`v` is the total sum of squares ``((y_true -\n",
       "y_true.mean()) ** 2).sum()``. The best possible score is 1.0 and it\n",
       "can be negative (because the model can be arbitrarily worse). A\n",
       "constant model that always predicts the expected value of `y`,\n",
       "disregarding the input features, would get a :math:`R^2` score of\n",
       "0.0.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "X : array-like of shape (n_samples, n_features)\n",
       "    Test samples. For some estimators this may be a precomputed\n",
       "    kernel matrix or a list of generic objects instead with shape\n",
       "    ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
       "    is the number of samples used in the fitting for the estimator.\n",
       "\n",
       "y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
       "    True values for `X`.\n",
       "\n",
       "sample_weight : array-like of shape (n_samples,), default=None\n",
       "    Sample weights.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "score : float\n",
       "    :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
       "``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
       "with default value of :func:`~sklearn.metrics.r2_score`.\n",
       "This influences the ``score`` method of all the multioutput\n",
       "regressors (except for\n",
       ":class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/opt/miniconda/lib/python3.8/site-packages/sklearn/base.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a899dd31",
   "metadata": {},
   "source": [
    "__Should we adjust the size of the test set? What would be the problem?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f05fc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set 0.05% | Score: 0.427\n",
      "Test Set 0.10% | Score: 0.537\n",
      "Test Set 0.20% | Score: 0.558\n",
      "Test Set 0.30% | Score: 0.451\n",
      "Test Set 0.40% | Score: 0.513\n",
      "Test Set 0.50% | Score: 0.475\n",
      "Test Set 0.60% | Score: 0.488\n",
      "Test Set 0.70% | Score: 0.439\n"
     ]
    }
   ],
   "source": [
    "for values in [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=values)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    score = model.score(X_test, Y_test)\n",
    "    \n",
    "    print(f\"Test Set {values:.2f}% | Score: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762cb4eb",
   "metadata": {},
   "source": [
    "There is a tradeoff between:\n",
    "- a big test set: score more accurate, but the fitting is less accurate (more bias)\n",
    "- a small test set: score more volatile, but the fitting is more accurate (more variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcba7200",
   "metadata": {},
   "source": [
    "__Implement $k$-fold model with $k=3$.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11451077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294, 10)\n",
      "(295, 10)\n",
      "(295, 10)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    print(X_train.shape)\n",
    "\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    score = model.score(X_test, Y_test)\n",
    "    \n",
    "    scores.append(score)\n",
    "    \n",
    "   ## train a model in X_train, y_train\n",
    "   ## test it on X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c1a7d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4693057771290108, 0.48724993937707484, 0.5095525852352711]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c73af8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4887027672471189"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(scores)/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74509f8b",
   "metadata": {},
   "source": [
    "__Bonus: use `statsmodels` (or `linearmodels`) to estimate the same linear model on the full sample. Is it always a superior method?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b2794457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4d4bf291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.DataFrame(X, columns=data['feature_names'])\n",
    "df['target'] = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bee43c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044528</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081414</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
       "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
       "\n",
       "           s4        s5        s6  target  \n",
       "0   -0.002592  0.019908 -0.017646   151.0  \n",
       "1   -0.039493 -0.068330 -0.092204    75.0  \n",
       "2   -0.002592  0.002864 -0.025930   141.0  \n",
       "3    0.034309  0.022692 -0.009362   206.0  \n",
       "4   -0.002592 -0.031991 -0.046641   135.0  \n",
       "..        ...       ...       ...     ...  \n",
       "437 -0.002592  0.031193  0.007207   178.0  \n",
       "438  0.034309 -0.018118  0.044485   104.0  \n",
       "439 -0.011080 -0.046879  0.015491   132.0  \n",
       "440  0.026560  0.044528 -0.025930   220.0  \n",
       "441 -0.039493 -0.004220  0.003064    57.0  \n",
       "\n",
       "[442 rows x 11 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e594251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "63f89ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model = api.ols('target ~ age + sex + bmi + bp + s1 + s2 + s3 + s4 + s5 + s6', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "61770048",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ols_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1dd48197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>target</td>      <th>  R-squared:         </th> <td>   0.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.507</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   46.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 16 Mar 2022</td> <th>  Prob (F-statistic):</th> <td>3.83e-62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:59:29</td>     <th>  Log-Likelihood:    </th> <td> -2386.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   442</td>      <th>  AIC:               </th> <td>   4794.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   431</td>      <th>  BIC:               </th> <td>   4839.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  152.1335</td> <td>    2.576</td> <td>   59.061</td> <td> 0.000</td> <td>  147.071</td> <td>  157.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>       <td>  -10.0122</td> <td>   59.749</td> <td>   -0.168</td> <td> 0.867</td> <td> -127.448</td> <td>  107.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex</th>       <td> -239.8191</td> <td>   61.222</td> <td>   -3.917</td> <td> 0.000</td> <td> -360.151</td> <td> -119.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bmi</th>       <td>  519.8398</td> <td>   66.534</td> <td>    7.813</td> <td> 0.000</td> <td>  389.069</td> <td>  650.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bp</th>        <td>  324.3904</td> <td>   65.422</td> <td>    4.958</td> <td> 0.000</td> <td>  195.805</td> <td>  452.976</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>s1</th>        <td> -792.1842</td> <td>  416.684</td> <td>   -1.901</td> <td> 0.058</td> <td>-1611.169</td> <td>   26.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>s2</th>        <td>  476.7458</td> <td>  339.035</td> <td>    1.406</td> <td> 0.160</td> <td> -189.621</td> <td> 1143.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>s3</th>        <td>  101.0446</td> <td>  212.533</td> <td>    0.475</td> <td> 0.635</td> <td> -316.685</td> <td>  518.774</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>s4</th>        <td>  177.0642</td> <td>  161.476</td> <td>    1.097</td> <td> 0.273</td> <td> -140.313</td> <td>  494.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>s5</th>        <td>  751.2793</td> <td>  171.902</td> <td>    4.370</td> <td> 0.000</td> <td>  413.409</td> <td> 1089.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>s6</th>        <td>   67.6254</td> <td>   65.984</td> <td>    1.025</td> <td> 0.306</td> <td>  -62.065</td> <td>  197.316</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.506</td> <th>  Durbin-Watson:     </th> <td>   2.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.471</td> <th>  Jarque-Bera (JB):  </th> <td>   1.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.017</td> <th>  Prob(JB):          </th> <td>   0.496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.726</td> <th>  Cond. No.          </th> <td>    227.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   R-squared:                       0.518\n",
       "Model:                            OLS   Adj. R-squared:                  0.507\n",
       "Method:                 Least Squares   F-statistic:                     46.27\n",
       "Date:                Wed, 16 Mar 2022   Prob (F-statistic):           3.83e-62\n",
       "Time:                        11:59:29   Log-Likelihood:                -2386.0\n",
       "No. Observations:                 442   AIC:                             4794.\n",
       "Df Residuals:                     431   BIC:                             4839.\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    152.1335      2.576     59.061      0.000     147.071     157.196\n",
       "age          -10.0122     59.749     -0.168      0.867    -127.448     107.424\n",
       "sex         -239.8191     61.222     -3.917      0.000    -360.151    -119.488\n",
       "bmi          519.8398     66.534      7.813      0.000     389.069     650.610\n",
       "bp           324.3904     65.422      4.958      0.000     195.805     452.976\n",
       "s1          -792.1842    416.684     -1.901      0.058   -1611.169      26.801\n",
       "s2           476.7458    339.035      1.406      0.160    -189.621    1143.113\n",
       "s3           101.0446    212.533      0.475      0.635    -316.685     518.774\n",
       "s4           177.0642    161.476      1.097      0.273    -140.313     494.442\n",
       "s5           751.2793    171.902      4.370      0.000     413.409    1089.150\n",
       "s6            67.6254     65.984      1.025      0.306     -62.065     197.316\n",
       "==============================================================================\n",
       "Omnibus:                        1.506   Durbin-Watson:                   2.029\n",
       "Prob(Omnibus):                  0.471   Jarque-Bera (JB):                1.404\n",
       "Skew:                           0.017   Prob(JB):                        0.496\n",
       "Kurtosis:                       2.726   Cond. No.                         227.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1146f9f3",
   "metadata": {},
   "source": [
    "## Sparse regressions on the Boston House Price Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d419464",
   "metadata": {},
   "source": [
    "__Import the Boston House Price Dataset from sklearn. Describe it. Compute correlations.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5552b49e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea3a4343",
   "metadata": {},
   "source": [
    "__Split the dataset into a training set (70%) and a test set (30%).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0c3ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2a7f35f",
   "metadata": {},
   "source": [
    "__Train a lasso model to predict house prices. Compute the score on the test set.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf980867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a37cbdd0",
   "metadata": {},
   "source": [
    "__Train a ridge model to predict house prices. Which one is better?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0077e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e8a6d84",
   "metadata": {},
   "source": [
    "__(bonus) Use statsmodels to build a model predicting house prices. What is the problem?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae54ad03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2a3edde",
   "metadata": {},
   "source": [
    "## Predicting Breast Cancer\n",
    "\n",
    "Sklearn includes the Winsconsin breast cancer database. It associates medical outcomes for tumor observation, with several characteristics. Can a machine learn how to predict whether a cancer is benign or malignant ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cff405",
   "metadata": {},
   "source": [
    "__Import the Breast Cancer Dataset from sklearn. Describe it.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5972a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef67cc58",
   "metadata": {},
   "source": [
    "__Properly train a linear logistic regression to predict cancer morbidity. (bonus: use k-fold validation)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788fc6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cc53545",
   "metadata": {},
   "source": [
    "__Try with other classifiers. Which one is best?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662aff0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
